{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4007\n",
      "137321: 1.0000000000000002\n",
      "49521: 0.14795060119427708\n",
      "28121: 0.13934315062065325\n",
      "10740: 0.13755252708246998\n",
      "36825: 0.13458319167989177\n"
     ]
    }
   ],
   "source": [
    "\n",
    "movies = pd.read_csv('./videos.csv')\n",
    "credits = pd.read_csv('./credits.csv')\n",
    "\n",
    "movies.head(2)\n",
    "\n",
    "movies.shape\n",
    "\n",
    "credits.head()\n",
    "\n",
    "movies = movies.merge(credits, on='title')\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies = movies[['movie_id', 'title', 'overview',\n",
    "                 'subject', 'keywords', 'cast', 'crew']]\n",
    "\n",
    "movies.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        L.append(i['name'])\n",
    "    return L\n",
    "\n",
    "\n",
    "movies.dropna(inplace=True)\n",
    "\n",
    "movies['subject'] = movies['subject'].apply(convert)\n",
    "movies.head()\n",
    "\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies.head()\n",
    "\n",
    "ast.literal_eval(\n",
    "    '[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]')\n",
    "\n",
    "\n",
    "\n",
    "def convert3(text):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(text):\n",
    "        if counter < 3:\n",
    "            L.append(i['name'])\n",
    "        counter += 1\n",
    "    return L\n",
    "\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert)\n",
    "movies.head()\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(lambda x: x[0:3])\n",
    "\n",
    "\n",
    "\n",
    "def fetch_director(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "    return L\n",
    "\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "# movies['overview'] = movies['overview'].apply(lambda x:x.split())\n",
    "movies.sample(5)\n",
    "\n",
    "\n",
    "\n",
    "def collapse(L):\n",
    "    L1 = []\n",
    "    for i in L:\n",
    "        L1.append(i.replace(\" \", \"\"))\n",
    "    return L1\n",
    "\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(collapse)\n",
    "movies['crew'] = movies['crew'].apply(collapse)\n",
    "movies['subject'] = movies['subject'].apply(collapse)\n",
    "movies['keywords'] = movies['keywords'].apply(collapse)\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
    "\n",
    "movies['tags'] = movies['overview'] + movies['subject'] + \\\n",
    "    movies['keywords'] + movies['cast'] + movies['crew']\n",
    "\n",
    "new = movies\n",
    "# new.head()\n",
    "\n",
    "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
    "new.head()\n",
    "\n",
    "\n",
    "\n",
    "class CountVectorizer:\n",
    "    def __init__(self, lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b\"):\n",
    "        self.lowercase = lowercase\n",
    "        self.token_pattern = token_pattern\n",
    "        self.vocabulary = defaultdict(int)\n",
    "        self.stop_words = set()\n",
    "\n",
    "    def fit_transform(self, raw_documents):\n",
    "        self.fit(raw_documents)\n",
    "        return self.transform(raw_documents)\n",
    "\n",
    "    def fit(self, raw_documents):\n",
    "        for doc in raw_documents:\n",
    "            tokens = self._tokenize(doc)\n",
    "            for token in tokens:\n",
    "                self.vocabulary[token] += 1\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, doc in enumerate(raw_documents):\n",
    "            tokens = self._tokenize(doc)\n",
    "            for token in tokens:\n",
    "                if token in self.vocabulary and token not in self.stop_words:\n",
    "                    rows.append(i)\n",
    "                    cols.append(self.vocabulary[token])\n",
    "                    data.append(1)\n",
    "        X = csr_matrix((data, (rows, cols)), shape=(\n",
    "            len(raw_documents), len(self.vocabulary)))\n",
    "        return X\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        if self.lowercase:\n",
    "            text = text.lower()\n",
    "        tokens = re.findall(self.token_pattern, text)\n",
    "        return tokens\n",
    "\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "new\n",
    "\n",
    "vector = cv.fit_transform(new['tags']).toarray()\n",
    "vector\n",
    "\n",
    "vector.shape\n",
    "\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the 'tags' column of the 'new' DataFrame\n",
    "tfidf_matrix = vectorizer.fit_transform(new['tags'])\n",
    "\n",
    "# Calculate the cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to generate recommendations\n",
    "\n",
    "\n",
    "def generate_recommendations(similarity_matrix, movie_id, top_k):\n",
    "    # Find the index of the movie with the given title\n",
    "    movie_index = new[new['movie_id'] == movie_id].index[0]\n",
    "    print(movie_index)\n",
    "    # Get the similarity scores for the movie\n",
    "    movie_scores = similarity_matrix[movie_index]\n",
    "\n",
    "    # Sort the movies based on similarity scores\n",
    "    sorted_indices = np.argsort(movie_scores)[::-1]\n",
    "    sorted_scores = movie_scores[sorted_indices]\n",
    "    sorted_titles = new.iloc[sorted_indices]['movie_id'].values\n",
    "\n",
    "    # Select the top k recommendations\n",
    "    top_recommendations = list(\n",
    "        zip(sorted_titles[:top_k], sorted_scores[:top_k]))\n",
    "\n",
    "    return top_recommendations\n",
    "\n",
    "\n",
    "# Generate recommendations for a movie\n",
    "recommendations = generate_recommendations(similarity_matrix, 137106, 5)\n",
    "\n",
    "# Print the recommendations\n",
    "for title, score in recommendations:\n",
    "    print(f\"{title}: {score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
